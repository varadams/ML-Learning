{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_mnist.pkl\", \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "\n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "train_labels_one_hot = data[4]\n",
    "test_labels_one_hot = data[5]\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       ...,\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       ...,\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [8.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        ...,\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]]),\n",
       " array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        ...,\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]]),\n",
       " array([[5.],\n",
       "        [0.],\n",
       "        [4.],\n",
       "        ...,\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [8.]]),\n",
       " array([[7.],\n",
       "        [2.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]]),\n",
       " array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.99, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        ...,\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.99, 0.01]]),\n",
       " array([[0.01, 0.01, 0.01, ..., 0.99, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.99, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.99, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        ...,\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "        [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@np.vectorize\n",
    "Define a vectorized function which takes a nested sequence of objects or numpy arrays as inputs and returns a single numpy array or a tuple of numpy arrays. The vectorized function evaluates pyfunc over successive tuples of the input arrays like the python map function, except it uses the broadcasting rules of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1/ (1+np.e**-x)\n",
    "activation_function = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on truncnorm_gen in module scipy.stats._continuous_distns object:\n",
      "\n",
      "class truncnorm_gen(scipy.stats._distn_infrastructure.rv_continuous)\n",
      " |  truncnorm_gen(momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |  \n",
      " |  A truncated normal continuous random variable.\n",
      " |  \n",
      " |  %(before_notes)s\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The standard form of this distribution is a standard normal truncated to\n",
      " |  the range [a, b] --- notice that a and b are defined over the domain of the\n",
      " |  standard normal.  To convert clip values for a specific mean and standard\n",
      " |  deviation, use::\n",
      " |  \n",
      " |      a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
      " |  \n",
      " |  `truncnorm` takes :math:`a` and :math:`b` as shape parameters.\n",
      " |  \n",
      " |  %(after_notes)s\n",
      " |  \n",
      " |  %(example)s\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      truncnorm_gen\n",
      " |      scipy.stats._distn_infrastructure.rv_continuous\n",
      " |      scipy.stats._distn_infrastructure.rv_generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      " |  \n",
      " |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  cdf(self, x, *args, **kwds)\n",
      " |      Cumulative distribution function of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cdf : ndarray\n",
      " |          Cumulative distribution function evaluated at `x`\n",
      " |  \n",
      " |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      " |      Calculate expected value of a function with respect to the\n",
      " |      distribution by numerical integration.\n",
      " |      \n",
      " |      The expected value of a function ``f(x)`` with respect to a\n",
      " |      distribution ``dist`` is defined as::\n",
      " |      \n",
      " |                  ub\n",
      " |          E[f(x)] = Integral(f(x) * dist.pdf(x)),\n",
      " |                  lb\n",
      " |      \n",
      " |      where ``ub`` and ``lb`` are arguments and ``x`` has the ``dist.pdf(x)`` \n",
      " |      distribution. If the bounds ``lb`` and ``ub`` correspond to the \n",
      " |      support of the distribution, e.g. ``[-inf, inf]`` in the default \n",
      " |      case, then the integral is the unrestricted expectation of ``f(x)``. \n",
      " |      Also, the function ``f(x)`` may be defined such that ``f(x)`` is ``0`` \n",
      " |      outside a finite interval in which case the expectation is \n",
      " |      calculated within the finite range ``[lb, ub]``. \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, optional\n",
      " |          Function for which integral is calculated. Takes only one argument.\n",
      " |          The default is the identity mapping f(x) = x.\n",
      " |      args : tuple, optional\n",
      " |          Shape parameters of the distribution.\n",
      " |      loc : float, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : float, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      lb, ub : scalar, optional\n",
      " |          Lower and upper bound for integration. Default is set to the\n",
      " |          support of the distribution.\n",
      " |      conditional : bool, optional\n",
      " |          If True, the integral is corrected by the conditional probability\n",
      " |          of the integration interval.  The return value is the expectation\n",
      " |          of the function, conditional on being in the given interval.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Additional keyword arguments are passed to the integration routine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expect : float\n",
      " |          The calculated expected value.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The integration behavior of this function is inherited from\n",
      " |      `scipy.integrate.quad`. Neither this function nor\n",
      " |      `scipy.integrate.quad` can verify whether the integral exists or is\n",
      " |      finite. For example ``cauchy(0).mean()`` returns ``np.nan`` and\n",
      " |      ``cauchy(0).expect()`` returns ``0.0``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      To understand the effect of the bounds of integration consider \n",
      " |      >>> from scipy.stats import expon\n",
      " |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0)\n",
      " |      0.6321205588285578\n",
      " |      \n",
      " |      This is close to \n",
      " |      \n",
      " |      >>> expon(1).cdf(2.0) - expon(1).cdf(0.0)\n",
      " |      0.6321205588285577\n",
      " |      \n",
      " |      If ``conditional=True``\n",
      " |      \n",
      " |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0, conditional=True)\n",
      " |      1.0000000000000002\n",
      " |      \n",
      " |      The slight deviation from 1 is due to numerical integration.\n",
      " |  \n",
      " |  fit(self, data, *args, **kwds)\n",
      " |      Return MLEs for shape (if applicable), location, and scale\n",
      " |      parameters from data.\n",
      " |      \n",
      " |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      " |      the fit are given by input arguments; for any arguments not provided\n",
      " |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      " |      such.\n",
      " |      \n",
      " |      One can hold some parameters fixed to specific values by passing in\n",
      " |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      " |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      " |      respectively).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to use in calculating the MLEs.\n",
      " |      args : floats, optional\n",
      " |          Starting value(s) for any shape-characterizing arguments (those not\n",
      " |          provided will be determined by a call to ``_fitstart(data)``).\n",
      " |          No default value.\n",
      " |      kwds : floats, optional\n",
      " |          Starting values for the location and scale parameters; no default.\n",
      " |          Special keyword arguments are recognized as holding certain\n",
      " |          parameters fixed:\n",
      " |      \n",
      " |          - f0...fn : hold respective shape parameters fixed.\n",
      " |            Alternatively, shape parameters to fix can be specified by name.\n",
      " |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      " |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      " |            equivalent to ``f1``.\n",
      " |      \n",
      " |          - floc : hold location parameter fixed to specified value.\n",
      " |      \n",
      " |          - fscale : hold scale parameter fixed to specified value.\n",
      " |      \n",
      " |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      " |            and starting position as the first two arguments,\n",
      " |            plus ``args`` (for extra arguments to pass to the\n",
      " |            function to be optimized) and ``disp=0`` to suppress\n",
      " |            output as keyword arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mle_tuple : tuple of floats\n",
      " |          MLEs for any shape parameters (if applicable), followed by those\n",
      " |          for location and scale. For most random variables, shape statistics\n",
      " |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This fit is computed by maximizing a log-likelihood function, with\n",
      " |      penalty applied for samples outside of range of the distribution. The\n",
      " |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      " |      may only be locally optimal, or the optimization may fail altogether.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate some data to fit: draw random variates from the `beta`\n",
      " |      distribution\n",
      " |      \n",
      " |      >>> from scipy.stats import beta\n",
      " |      >>> a, b = 1., 2.\n",
      " |      >>> x = beta.rvs(a, b, size=1000)\n",
      " |      \n",
      " |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      " |      \n",
      " |      We can also use some prior knowledge about the dataset: let's keep\n",
      " |      ``loc`` and ``scale`` fixed:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      " |      >>> loc1, scale1\n",
      " |      (0, 1)\n",
      " |      \n",
      " |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      " |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      " |      equivalently, ``fa=1``:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      " |      >>> a1\n",
      " |      1\n",
      " |      \n",
      " |      Not all distributions return estimates for the shape parameters.\n",
      " |      ``norm`` for example just returns estimates for location and scale:\n",
      " |      \n",
      " |      >>> from scipy.stats import norm\n",
      " |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      " |      >>> loc1, scale1 = norm.fit(x)\n",
      " |      >>> loc1, scale1\n",
      " |      (0.92087172783841631, 2.0015750750324668)\n",
      " |  \n",
      " |  fit_loc_scale(self, data, *args)\n",
      " |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to fit.\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Lhat : float\n",
      " |          Estimated location parameter for the data.\n",
      " |      Shat : float\n",
      " |          Estimated scale parameter for the data.\n",
      " |  \n",
      " |  isf(self, q, *args, **kwds)\n",
      " |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          upper tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : ndarray or scalar\n",
      " |          Quantile corresponding to the upper tail probability q.\n",
      " |  \n",
      " |  logcdf(self, x, *args, **kwds)\n",
      " |      Log of the cumulative distribution function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logcdf : array_like\n",
      " |          Log of the cumulative distribution function evaluated at x\n",
      " |  \n",
      " |  logpdf(self, x, *args, **kwds)\n",
      " |      Log of the probability density function at x of the given RV.\n",
      " |      \n",
      " |      This uses a more numerically accurate calculation if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logpdf : array_like\n",
      " |          Log of the probability density function evaluated at x\n",
      " |  \n",
      " |  logsf(self, x, *args, **kwds)\n",
      " |      Log of the survival function of the given RV.\n",
      " |      \n",
      " |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      " |      evaluated at `x`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logsf : ndarray\n",
      " |          Log of the survival function evaluated at `x`.\n",
      " |  \n",
      " |  nnlf(self, theta, x)\n",
      " |      Return negative loglikelihood function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      " |      parameters (including loc and scale).\n",
      " |  \n",
      " |  pdf(self, x, *args, **kwds)\n",
      " |      Probability density function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          Probability density function evaluated at x\n",
      " |  \n",
      " |  ppf(self, q, *args, **kwds)\n",
      " |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          lower tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : array_like\n",
      " |          quantile corresponding to the lower tail probability q.\n",
      " |  \n",
      " |  sf(self, x, *args, **kwds)\n",
      " |      Survival function (1 - `cdf`) at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sf : array_like\n",
      " |          Survival function evaluated at x\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __call__(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  entropy(self, *args, **kwds)\n",
      " |      Differential entropy of the RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional  (continuous distributions only).\n",
      " |          Scale parameter (default=1).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Entropy is defined base `e`:\n",
      " |      \n",
      " |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      " |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      " |      True\n",
      " |  \n",
      " |  freeze(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  interval(self, alpha, *args, **kwds)\n",
      " |      Confidence interval with equal areas around the median.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array_like of float\n",
      " |          Probability that an rv will be drawn from the returned range.\n",
      " |          Each value should be in the range [0, 1].\n",
      " |      arg1, arg2, ... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a, b : ndarray of float\n",
      " |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      " |          possible values.\n",
      " |  \n",
      " |  mean(self, *args, **kwds)\n",
      " |      Mean of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : float\n",
      " |          the mean of the distribution\n",
      " |  \n",
      " |  median(self, *args, **kwds)\n",
      " |      Median of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : float\n",
      " |          The median of the distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      stats.distributions.rv_discrete.ppf\n",
      " |          Inverse of the CDF\n",
      " |  \n",
      " |  moment(self, n, *args, **kwds)\n",
      " |      n-th order non-central moment of distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, n >= 1\n",
      " |          Order of moment.\n",
      " |      arg1, arg2, arg3,... : float\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |  \n",
      " |  rvs(self, *args, **kwds)\n",
      " |      Random variates of given type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Defining number of random variates (default is 1).\n",
      " |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      " |          If int or RandomState, use it for drawing the random variates.\n",
      " |          If None, rely on ``self.random_state``.\n",
      " |          Default is None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rvs : ndarray or scalar\n",
      " |          Random variates of given `size`.\n",
      " |  \n",
      " |  stats(self, *args, **kwds)\n",
      " |      Some statistics of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional (continuous RVs only)\n",
      " |          scale parameter (default=1)\n",
      " |      moments : str, optional\n",
      " |          composed of letters ['mvsk'] defining which moments to compute:\n",
      " |          'm' = mean,\n",
      " |          'v' = variance,\n",
      " |          's' = (Fisher's) skew,\n",
      " |          'k' = (Fisher's) kurtosis.\n",
      " |          (default is 'mv')\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stats : sequence\n",
      " |          of requested moments.\n",
      " |  \n",
      " |  std(self, *args, **kwds)\n",
      " |      Standard deviation of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : float\n",
      " |          standard deviation of the distribution\n",
      " |  \n",
      " |  var(self, *args, **kwds)\n",
      " |      Variance of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : float\n",
      " |          the variance of the distribution\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  random_state\n",
      " |      Get or set the RandomState object for generating random variates.\n",
      " |      \n",
      " |      This can be either None or an existing RandomState object.\n",
      " |      \n",
      " |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      " |      If already a RandomState instance, use it.\n",
      " |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(truncnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rvs in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "rvs(*args, **kwds) method of scipy.stats._continuous_distns.truncnorm_gen instance\n",
      "    Random variates of given type.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arg1, arg2, arg3,... : array_like\n",
      "        The shape parameter(s) for the distribution (see docstring of the\n",
      "        instance object for more information).\n",
      "    loc : array_like, optional\n",
      "        Location parameter (default=0).\n",
      "    scale : array_like, optional\n",
      "        Scale parameter (default=1).\n",
      "    size : int or tuple of ints, optional\n",
      "        Defining number of random variates (default is 1).\n",
      "    random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      "        If int or RandomState, use it for drawing the random variates.\n",
      "        If None, rely on ``self.random_state``.\n",
      "        Default is None.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rvs : ndarray or scalar\n",
      "        Random variates of given `size`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(truncnorm.rvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.152902630181526"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncnorm.rvs(1,2,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal(mean = 0,sd = 1, low = 0, upp = 10):\n",
    "    return truncnorm((low-mean)/sd,(upp - mean)/sd,loc = mean, scale = sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    " \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "            \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "    \n",
    "        \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" \n",
    "        A method to initialize the weight matrices \n",
    "        of the neural network with optional \n",
    "        bias nodes\"\"\"\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        \n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
    "                          self.no_of_in_nodes + bias_node))\n",
    "\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, \n",
    "                             sd=1, \n",
    "                             low=-rad, \n",
    "                             upp=rad)\n",
    "        self.who = X.rvs((self.no_of_out_nodes, \n",
    "                          self.no_of_hidden_nodes + bias_node))\n",
    "        \n",
    " \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple, \n",
    "        list or ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, \n",
    "                                            [self.bias]) )\n",
    "        \n",
    "        output_vectors = []\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, \n",
    "                                input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_hidden = np.concatenate((output_hidden, \n",
    "                                            [[self.bias]]) )\n",
    "\n",
    "        \n",
    "        output_vector2 = np.dot(self.who, \n",
    "                                output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_network * (1.0 - output_network)          \n",
    "        tmp = self.learning_rate  * np.dot(tmp, \n",
    "                                           output_hidden.T) \n",
    "        self.who += tmp\n",
    "\n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, \n",
    "                               output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.wih += self.learning_rate * x\n",
    "        \n",
    "\n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        intermediate_weights = []\n",
    "        for epoch in range(epochs):  \n",
    "            for i in range(len(data_array)):\n",
    "                self.train_single(data_array[i], \n",
    "                                  labels_one_hot_array[i])\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.wih.copy(), \n",
    "                                             self.who.copy()))\n",
    "        return intermediate_weights      \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, \n",
    "                                            [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        output_vector = np.dot(self.wih, \n",
    "                               input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, \n",
    "                                             [[self.bias]]) )\n",
    "            \n",
    "\n",
    "        output_vector = np.dot(self.who, \n",
    "                               output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "accruracy train:  0.9464333333333333\n",
      "accruracy test:  0.9442\n",
      "epoch:  1\n",
      "accruracy train:  0.9638\n",
      "accruracy test:  0.9596\n",
      "epoch:  2\n",
      "accruracy train:  0.96995\n",
      "accruracy test:  0.964\n",
      "epoch:  3\n",
      "accruracy train:  0.9723666666666667\n",
      "accruracy test:  0.964\n",
      "epoch:  4\n",
      "accruracy train:  0.9747833333333333\n",
      "accruracy test:  0.9643\n",
      "epoch:  5\n",
      "accruracy train:  0.9755833333333334\n",
      "accruracy test:  0.9641\n",
      "epoch:  6\n",
      "accruracy train:  0.9752666666666666\n",
      "accruracy test:  0.9629\n",
      "epoch:  7\n",
      "accruracy train:  0.9781166666666666\n",
      "accruracy test:  0.9668\n",
      "epoch:  8\n",
      "accruracy train:  0.97705\n",
      "accruracy test:  0.9633\n",
      "epoch:  9\n",
      "accruracy train:  0.9783833333333334\n",
      "accruracy test:  0.9634\n",
      "epoch:  10\n",
      "accruracy train:  0.9760166666666666\n",
      "accruracy test:  0.9614\n",
      "epoch:  11\n",
      "accruracy train:  0.97625\n",
      "accruracy test:  0.9607\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "\n",
    "network = NeuralNetwork(no_of_in_nodes=image_pixels, \n",
    "                        no_of_out_nodes=10, \n",
    "                        no_of_hidden_nodes=100,\n",
    "                        learning_rate=0.1,\n",
    "                        bias=None)\n",
    "\n",
    "weights = network.train(train_imgs, \n",
    "                        train_labels_one_hot, \n",
    "                        epochs=epochs, \n",
    "                        intermediate_results=True) \n",
    "for epoch in range(epochs):  \n",
    "    print(\"epoch: \", epoch)\n",
    "    network.wih = weights[epoch][0]\n",
    "    network.who = weights[epoch][1]\n",
    "    corrects, wrongs = network.evaluate(train_imgs, \n",
    "                                        train_labels)\n",
    "    print(\"accruracy train: \", corrects / ( corrects + wrongs))                   \n",
    "    corrects, wrongs = network.evaluate(test_imgs, \n",
    "                                        test_labels)\n",
    "    print(\"accruracy test: \", corrects / ( corrects + wrongs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
